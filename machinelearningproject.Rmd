---
output: html_document
---
**Executive Summary**
The HAR (human activity recognition)data set can be obtained [here](http://groupware.les.inf.puc-rio.br/har). This dataset contains six subjects who were asked to do barbell lifts correctly (classe=A) and incorrectly several ways (classe= A, B, C,and D). The goal of this project is to create a model to predict the activity class a subject is performing. Several different types of classification models were constructed, however, the random forest model was by far the most accurate at 99% and OOB error less than 1 %. This model was able to succesfully predict the activity class from 20 unknown samples. 

**Loading and cleaning up data**

Load libraries and data.
```{r, message=FALSE, warning = FALSE}
library(ggplot2);library(caret);library(randomForest);library(rattle)
library(rpart);library(rpart.plot)
traindata<-read.csv("training.csv", na.strings=c("", "NA"), header= TRUE)
testdata<-read.csv("testing.csv", header= TRUE)
```
 

There are many columns in the traindata with a large proportion (over 90%) of missing data. I chose to keep only columns that have less than 10000 NAs. Now there are no missing data in the dataset. 
```{r}
count <- sapply(traindata, is.na);count <- colSums(count);
traindata <- traindata[,count<10000]
```


The first seven variables are subject IDs, timestamps and are likely unrelated to activity class. I removed thsee and convered the data to numeric, while leave the "classe" variable as a factor.
```{r}
traindata<-traindata[,-c(1:7)]; 
traindata[,1:52]<-as.numeric(as.matrix(traindata[,1:52]))
```

Next, I removed highly correlated variables with a coeffecient greater than .75. Now the dataset has 32 predictors and one outcome, "classe".
```{r}
traindataCor <-  cor(traindata[,1:52])
high.corr<-findCorrelation(traindataCor, cutoff=.75)
traindata<-traindata[,-high.corr]
```

**Cross Validation Method**

I split the training data into subset 70% in training 30% test. This will allow for a hold-out method of cross validation when testing model accuracy later. 

```{r}
inTrain<-createDataPartition(y=traindata$classe, p=.70, list=FALSE)
subtraining<-traindata[inTrain,]
subtest<-traindata[-inTrain,]
```

**Building Classification Models**

The first model I created is a recursive partitioning model with the rpart package. 
```{r, message=FALSE, warning = FALSE}
set.seed(3780)
modelrpart<-rpart(classe~., data= subtraining, method = "class")
prp(modelrpart,main = "Classification tree from rpart model", 
        type=2, cex = .7, fallen.leaves= TRUE)
```

Cross validation with the subtest set we set aside earlier gives 67.7%  accuracy for out of sample error. 
```{r, warning=FALSE}
prediction<-predict(modelrpart, newdata=subtest, type = "class")
confusionMatrix(prediction, subtest$classe)
pred.table<-table(prediction,subtest$classe)/length(subtest$classe)
sum(diag(pred.table))
```


**The Random Forest Model**

The random forest model constructs trees using a bootstrap sample of the data (bootstrap with replacement). Each tree is constructed with about 1/3 of the data. The out-of-bag data is used to get a running estimate of the classification error, which eliminates the need for cross-validation like we did with the rpart model previously. This particular RF model was constructed with only 100 trees for increased speed gives 99.13% accuracy and out-of-bat (OOB) error rate less than one percent (.84%).  

```{r}
set.seed(1234)
modelFit<-randomForest(classe~., data = subtraining, 
        type = "rf", ntree=100, proximity=TRUE)
modelFit
```

In the random forest model, the error rate drastically declines in the first 20 trees and levels out at after about 40 to 50 trees have been drawn. I would not expect to get much more accuracy by increasing number of trees for this particular dataset. 
```{r}
par(mar=c(4,4,4,2))
plot(modelFit, main = "Error rate by number of trees\n in the RF model")
legend("topright", title = "Classe", legend=unique(modelFit$classe), 
        col=unique(as.numeric(modelFit$classe)), fill=1:5, pch=19)
```

Using the RF model to predict "classe" from the subtest data, shows this model is quite accurate (99%). The confusion matrix shows most are classified correctly.

```{r}
predictions<-predict(modelFit, newdata=subtest)
confusionMatrix(predictions, subtest$classe)
```


These are the top variables in decreasing order of importance in the random forest model.
```{r}
varImpPlot(modelFit, main  = "Top 15 most important variables\n in the random forest model", 
          scale=TRUE, n.var=15)
```

**Predictions with testdata**
Using the most accurate model, the random forest model, I correctly predicted 20 variables of unknown "classe".
```{r}
as.character(predict(modelFit, newdata=testdata))
```

**Conclusions**
Of the models created to predict activity class from the HAR dataset, the random forest model performed the best with an accuracy of 99% and a low OOB error rate .84. 
